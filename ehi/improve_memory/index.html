<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Systems to improve long-term memory</title>
    <link rel="stylesheet" href="style.css">
  </head>

  <body>

    <div id="header">
      <h1>Systems to improve long-term memory</h1>
      <p>
	<a href="http://michaelnielsen.org">Michael Nielsen</a> &nbsp; / &nbsp;	December 2016
      </p>
    </div>

    <div id="container">
      <p>
	<em>Summary: An explanation of the spacing effect and the lag
	effect in our long-term memory.  How these can be used to
	build systems to improve long-term memory.  How many existing
	practices actually violate these ideas.
	</em>
      </p>

      <span class="marginnote">
	Rough working notes, based on a discussion with Caitlin Sikora,
	Katherin Ye, Nicky Case, Xavier Snelgrove, and Yan Zhu.
	Supported by <a href="http://ycr.org">Y Combinator Research</a>,
	based on work begun at the <a href="http://recurse.com">Recurse
	  Center</a>.
      </span>
      
    <p>
      Let me show you a flashcard program
      called <a href="http://ankirs.net">Anki</a>.  Here's one of my
      flashcards, asking how much solar radiation is received at the
      surface of the Earth:
    </p>

    <img src="assets/Anki_initial_card.png"/>

    <p>
      When shown a card, you pause to consider your answer to the
      question.  Then you ask Anki to reveal the correct answer
      &ndash; for this question, 1,367 Watts of power, per square
      meter &ndash; and compare with your own response:
    </p>

    <img src="assets/Anki_initial_answer.png"/>

    <p>
      If you look closely at the bottom of the card you'll see buttons
      marked &ldquo;Again&rdquo;, &ldquo;Hard&rdquo;,
      &ldquo;Good&rdquo; and &lsquo;Easy&rdquo;.  These buttons allow
      you to grade your answer.  If you got the question wrong you
      tell the program you want to see the card &ldquo;Again&rdquo;.
      If you got the question right, but struggled with it, you select
      &ldquo;Hard&rdquo;.  If you got the question right with relative
      ease, you select &ldquo;Good&rdquo;.  Finally, if you found the
      question trivially easy, you select &ldquo;Easy&rdquo;.
    </p>
    
    <p>
      Which option you select determines how long before you see the
      card again.  If you selected &ldquo;Again&rdquo;, the card goes
      back in the queue of cards which are currently due, i.e., cards
      to be shown as soon as possible.  But if you selected any of the
      other three options, Anki will delay before showing you the card
      again.
    </p>

    <p>
      How are the delays chosen?
    </p>

    <p>
      There is research suggesting that a memory is strengthened most
      if you're tested on it when you're just on the verge of
      forgetting it.  This is sometimes known as the <em>retrieval
      effort hypothesis</em>.  And so you can minimize your total
      study time by studying at those times.  Ideaaly, Anki would show
      you the flashcard just as you were reaching that time.
    </p>

    <p>
      In practice, Anki doesn't know exactly when you're on the verge
      of forgetting something.  So it uses some heuristics to
      approximate that time.  The initial delay before being tested is
      1 day.  If you select &ldquo;Good&rdquo; when you answer, that
      is increased by a factor 2.5, to 2.5 days.  If you select
      &ldquo;Good&rdquo; again, it increases by another factor 2.5, to
      6.25 days.  And so on, through ever-increasing delays.  By
      contrast, if you select &ldquo;Hard&rdquo;, that tells Anki you
      find the card difficult, and so the factor 2.5 &ndash; known as
      the card's &ldquo;Ease&rdquo; &ndash; is adjusted to be smaller.
      On the other hand, if you select &ldquo;Easy&rdquo;, the card's
      ease is adjusted upward, and the delay between repetitions
      increases even more rapidly*<span class="marginnote">* There's
      some details of how Anki changes delays that I've glossed over.
      The description in this paragraph merely summarizes the main
      ideas. </span>.
    </p>

    <p>
      In this essay I discuss how software systems may aid our
      long-term memory.  I'll address the following questions:
      <ul>
	<li>What do we (and don't we) know about the cognitive science
	  behind memory aids such as Anki?</li>

	<li>How much use are memory aids, anyway?  Why haven't
	  cognitive scientists done more to build systems based on
	  these concepts?  Why aren't they used broadly, at
	  scale?</li>
	
	<li>Are there ways we can improve on systems such as Anki?
	I'll describe several design ideas for building better
	  systems.</li>

	<li>Is it possible to incorporate these ideas into the design
	not just of flashcard programs, but into other software
	systems?</li>

	<li>How do current practices fail to take advantage of these
	ideas?  In fact, as we'll see, some common current practices
	  actively violate what we know about how memory works.</li>
      </ul>
    </p>

    <h2>Distributed practice</h2>
    
    <p>
      Anki is based around many ideas from cognitive science.  In this
      section we'll take a brief look at two of these ideas, the lag
      effect and the testing effect.  We'll come back and look in more
      detail at each later.
    </p>

    <P>
      Suppose you have 100 cardboard flashcards, which you're using to
      study 100 words of Russian vocabulary.  One approach to studying
      is to review each card once today, taking you 15 minutes, and
      then each card once again tomorrow, again taking you 15 minutes.
      Another approach is to review all the cards twice each tomorrow,
      taking you 30 minutes.  The <em>spacing effect</em> predicts
      that if you're tested on the cards in a week, you'll do much
      better if you use the first approach.  That is, it's better to
      space out your study, rather than to use massed presentation
      (i.e., cramming).  What's more, the effect is not small: even
      simple spacing strategies can double or more the speed at which
      you learn.
    </P>

    <p>
      How should we space out our study?
    </p>

    <p>
      In 1885, the German psychologist Hermann Ebbinghaus published
      experiments*<span class="marginnote">* Published in a translated
      English text
      as <a href="https://archive.org/details/memoryacontribu00ebbigoog">Memory:
      a Contribution to Experimental Psychology</a> (Teachers College,
      Columbia University, 1913).</span> from which he empirically
      deduced a <em>forgetting curve</em>.  What Ebbinghaus found is
      that after learning a new fact, the associated memory decays
      exponentially.  In particular, the probability of later recall
      when tested looks like this:
    </p>

    <center>
      <canvas id="forgetting" width="600" height="400"></canvas>
    </center>

    <p>
      As you can see, immediately after learning the fact, the
      probability of recall is 1.  After that the probability decays
      exponentially, unless the memory is recalled to mind in the
      intervening time, before being tested.  We can express the
      probability through the equation
    </p>

    <p>
      <em>p</em> = 2<sup>-<em>t</em>/<em>h</em></sup>,
    </p>

    <p>
      where <em>p</em> is the probability of recall, <em>t</em> is the
      time since the fact was learned, and <em>h</em> is the
      <em>half-life</em> of the memory, that is, the length of time
      that must elapse for the probability to decrease to &frac12;.
      The longer the half-life, the more strongly the memory is
      stored.  Ideally, the half-life is <em>h</em>
      = <em>&infin;</em>, that is, you'd never forget the fact, no
      matter how long you wait.
    </p>

    <p>
      So far, I've been talking about what happens in a single test.
      What happens if you are repeatedly tested, as in a flashcard
      program such as Anki?  In that case, according to Ebbinghaus's
      model, you get repeated exponential decays:
    </p>

    <center>
      <canvas id="forgetting_repeated" width="600" height="400"></canvas>
    </center>

    <p>
      Note that after testing the probability of recall goes back up
      to 1, because you're reminded of the correct answer.  And then
      it begins to decay exponentially again.  However, there's an
      important change: the memory half-life gets longer each time
      you're tested.  Put another way, after each round of testing the
      memory is stored much better, and so we can wait longer between
      practices.  This gradual increase in half-life is known as
      the <em>lag effect</em>.  When combined with the spacing effect,
      as in Anki's increasing delays between cards, we'll call the
      idea <em>distributed practice</em>.
    </p>

    <p>
      As an aside, the exact shape of the forgetting curve is still
      the subject of ongoing study.  Ebbinghaus's exponential model is
      best thought of as a useful first approximation, not as the
      final word.  This poses a problem for my earlier definition of
      the lag effect.  Obviously, we can't define the lag effect as
      the &ldquo;memory half-life getting longer&rdquo;, when the
      notion of a memory half-life was defined in terms of the
      exponential decay.  Nonetheless, regardless of the shape of the
      forgetting curve, many studies show that repeated testing
      strengthens memories, so it takes longer before the probability
      of recall falls to any given level.  And so the lag effect makes
      sense and often holds, even if the exponential decay curve does
      not.
    </p>

    <p>
      Distributed practice can considerably reduce the time required
      to commit a fact to memory.  On average, after more than a year
      of using Anki, I answer more than 94 percent of flashcards
      correctly.  Assuming that continues to hold, it means that for a
      typical card I can expect to be tested on the card about 17
      times before an error.  With the way Anki increases the delays
      between tests, that more than covers my entire lifetime.  In
      fact, about 11 tests should cover the remainder of my life.  On
      average, each test takes about 8 seconds.  So that's a total of
      under 2 minutes total lifetime study, to commit a fact to
      memory.
    </p>
    
    <p>
      Of course, there are many caveats to this discussion.  But it's
      useful as a rough picture of how distributed practice works.
    </p>

    <h2>Anki in practice</h2>

    <p>
      Let me make a few personal observations, both positive and
      negative, based on more than a year's regular use of Anki.  At
      the outset, I will say that after some initial hiccups I've had
      a very positive experience with Anki, and I won't try to hide
      that behind a false appearance of &ldquo;objective&rdquo;
      neutrality.  On the other hand, there are significant drawbacks
      and room for improvement in such systems, and I'm trying to get
      to the bottom of that.  The observations that follow are far
      from complete.  But they establish a few of the most important
      observations I've made while using Anki.
    </p>

    <p>
      <strong>Statistics:</strong> As I write these words, Anki's
      statistics show that I've studied 341 of the past 381 days.
      I've averaged 142 reviews and 20 minutes per day, on those days
      I've studied.  Each review has taken an average of 8 seconds.
      5,546 Anki cards have <em>matured</em> in that time, i.e., I've
      reviewed them often enough that Anki considers the knowledge
      reasonably reliably committed to memory.
    </p>

    <p>
      <strong>The certainty effect:</strong> One of the main benefits
      of Anki has been that if I want to remember something, I can now
      simply <em>choose</em> to do so.  In the past, if I was reading
      a paper or book, my memory was unreliable.  Of course, if I made
      enough effort I could guarantee recall of particular things.
      But in general I was at the mercy of an unreliable memory.
      That's no longer true.
    </p>

    <p>
      As an example, I decided to memorize everything that seemed
      useful from a short book on the command line shell.  I estimate
      I memorized more than 50 percent of the API calls in the book
      &ndash; many hundreds of calls.  Doing so was easy and
      relatively quick, though tedious.  Most significantly, I
      simply <em>decided</em>, without much fuss, to do this, and the
      process happened more or less automatically.
    </p>

    <p>
      I've used Anki to memorize facts about APIs, about food and
      cooking, about restaraunts, about things to do in my new city of
      San Francisco.  I routinely use it while reading books and
      papers, and while studying videos.  I use it constantly in my
      research, to store insights that I expect to be of durable use.
    </p>
      
    <p>
      <strong>Why is distributed practice not so widely used?</strong>
      Ebbinghaus's work appeared in 1885, and was immediately widely
      praised.  William James, in his 1890 <em>The Principles of
      Psychology</em>, described Ebbinghaus's work at length, and
      lauded it as &ldquo;heroic&rdquo;.  A stream of followups were
      done, gradually growing into a flood.  I used <em>Google
      Scholar</em> to search for related work done since 2010; I
      stopped counting once I found more than 200 papers.  While we
      still have only a very incomplete understanding of why
      distributed practice works (of which more below), it's fair to
      say that the underlying effects are both strong and quite robust
      across materials.
    </p>

    <p>
      All of which makes it curious that distributed practice is
      underused.  Although many small-scale experiments have been
      done, it's not used systematically at scale in any educational
      system I'm aware of.
    </p>

    <p>
      Indeed, many educational practices actually run directly counter
      to the effect.  For example, textbooks often clump similar
      practice problems together, rather than spreading them out.  And
      many educational systems are based around large, infrequent
      exams, rather than very frequent testing.  Indeed, one of the
      more cited papers on the spacing
      effect*<span class="marginnote">* Frank
      N. Dempster, <a href="assets/Dempster1988.pdf">The Spacing
      Effect: A Case Study in the Failure to Apply the Results of
      Psychological Research</a> (1988).</span> actually aims to
      understand why it's been so underused.
    </p>

    <p>
      Now, it should be said that there are some widely-used
      educational practices
    </p>

    <p>
      <strong>Examples where it is conventional to violate distributed
      practice:</strong>
    </p>
      
    Making good cards is an art: There are many mistakes one can make
    in . And there are also There's actually a special kind of paying
    attention involved.

    Why is distributed practice not so widely used?
    
    
    <h2>Better ways of choosing the time to the next practice</h2>

    <p>
      I've described how Anki chooses the time to schedule the next
      practice.  Implicitly, we can think of that scheduling algorithm
      as a (very rough) theory of how long to delay until the next
    </p>

    <p>
      Is it possible to do better?
    </p>

    <p>
      The website <a href="https://duolingo.com">Duolingo</a> attempts
      to use machine learning to more accurately estimate the spacing
      between repetitions.  Duolingo is a popular site for learning
      new languages.  XXX - what Duolingo does.
    </p>

    <p>
      Duolingo has XXX users.  Suppose I sign up for the site, and
      starting learning Spanish.  Intuitively, it should be possible
      for Duolingo to estimate my performance on future quizzes by
      looking at the performance of other users whose profile of
      performance is similar to mine.  In this way, Duolingo can 
    </p>

    <p>
      A little more formally, Duolingo uses their existing data to
      build a model to estimate the half-life as a function of a
      student's past performance, and of the lexical complexity of the
      current.  They call this procedure <em>half-life
      regression</em>.  With that estimate, they can then estimate the
      optimal time to quizz me again in the future.
    </p>

    <p>
      I won't get into the details of their model.  Indeed, the model
      is frankly rather arbitrary.
    </p>
    

    
    Testing effect.  It's just a model.

    Structure: Explain the testing effect. Show a screenshot.
    Duolingo has recently begun using dist. practice.  But whereas
    Anki has a very crude model, Duolingo tries to build a slightly
    more sophisticated model.  In particular, they build a model which
    is able to estimate the half-life, based on past student
    behaviour, and on lexical knowledge of the word.  Intuitively, if
    someone gets a word right, adjust half-life up; if someone gets a
    word wrong, adjust half-life down, to oprimize some objective.
    It's still a relatively crude model, but they get some
    improvement.  Much more detailed work could be done.

    

    
    
    <h3>Distributed practice</h3>



    <p>
      The systems which do allow
      
    A curiosity is that it's been relatively little used. One of the
    most cited papers is actually to a discussion
    

    I said earlier that Anki will ideally show you a card just as you
    are about to forget the contents of that card.  This is badly
    broken when
    
    It's been studied a tremendous amount.  First review was in.
    Steady stream ever since.  More .  The picture is somewhat
    complex, a point I'll come back to. But the broad picture is 

    

    Why is this so little used?
    
    Curiosity: One strange thing about Sebasitan Leitner.  Piotr Wozniak.  One of the
    most-cited papers on the effect is about
    
    What we're going to do: We're going to poke around.  We're going
    to brainstorm

    First, though, I need to digress to talk a little about the role
    of cognitive science in all this.

    <p>
      <strong>Anti-patterns:</strong> It's not just that distributed
      practice isn't widely used in .  In fact a lot of conventional
      wisdom and widely used patterns of design <em>directly
      contradict</em> what we know about memory.
    </p>

    <p>
      For example, many textbooks clump subject matter together.  A
      geography textbook may clump material into topical sections.
      Everything on South Africa (including quiz questions) into this
      section!  Everything on Madagascar into that section!  And so
      on.  So you spend a day on South Africa, a day on Madagascar,
      and so on.  It'd be better to have the material &ndash;
      especially the quiz questions &ndash; spread out.
    </p>

    <p>
      A friend of mine frequently complains about the length of books.
      &ldquo;Good book&rdquo;, he'll say, &ldquo;but it got
      repetitive.  The content could have been covered in a few
      pages&rdquo;.  This is undoubtedly true of many books.  But I
      wonder if the benefit of having it spread out over 300 pages
      isn't to ensure some distributed practice.
    </p>
      
    The effect is lesser
    
    The research 


    What's the right schedule?  If it's 90+ percent, doesn't that
    suggest that we're being too conservative?  Why not auto-adjust?

    How useful is it all?  How useful is it to know the solar constant?

    I wonder if we can do a reverse NMR thing, basically writing
    thoughts?

    Can we incorporate into editors?  Into IDEs?  


    <p>
      <strong>Memorizing facts about people:</strong> .  When I
      started to do this, I noticed considerbale discomfort on my own
      part.  It revolves around several different taboos.  Don't treat
      people as objects.  Don't monitor other people overly closely.
      In a single word, the right test seems to be courtesy.  The
      litmus test is: would the other person be comfortable with this?
      That turns out to be a rather stringest test.  Knowing whether
      someone is vegan is fine.  Knowing their favourite foods is a
    </p>
      
	
    <h3>Acknowledgements</h3>


    <h3>Citation</h3>

    <p>
      In academic work, please cite this essay as: <em>Michael
	Nielsen, &ldquo;Tools to improve long-term memory&rdquo;,
	available
	at <a href="http://cognitivemedium.com/tat/index.html">http://cognitivemedium.com/ehi/improve_memory/index.html</a>
	(2016)</em>.
    </p>

    <p>
      In non-academic work, I'd appreciate it (and it would help me
      out) if you could give me a shout-out, too!
    </p>

    </div>    

    <div id="footer">
      This work is licensed under a <a rel="license"
	 href="http://creativecommons.org/licenses/by/4.0/">Creative
	 Commons Attribution 4.0 International License</a>.  This
	 means you're free to copy, share, and build on the work,
	 provided you attribute it appropriately.  Please click on the
	 following license link for details: <a rel="license"
	 href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative
	 Commons License" style="border-width: 0; height: 21px;"
	 src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
    </div>
<!--    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-44208967-4', 'auto');
      ga('send', 'pageview');
    </script>
-->

      <script src="js/memory.js">
      </script>

<!--    <script src="hybrid.js"></script> -->
  </body>
</html>  






