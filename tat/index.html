<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Thought as a Technology</title>
    <link rel="stylesheet" type="text/css" href="style.css">
    <link rel="stylesheet" type="text/css" href="js/demo/demo.css">
    <script src="js/demo/three.min.js"></script>
    <script src="js/demo/canvas.js"></script>
    <script src="js/demo/demo.js"></script>
    <script src="js/demo/interface_elements.js"></script>
  </head>

  <body>
    <div id="header">
      <h1>Thought as a Technology</h1>
      <p>
	<a href="http://michaelnielsen.org">Michael Nielsen</a> &nbsp; / &nbsp;	November 2016
      </p>
    </div>

    <div id="container">
      <p>
	Have you ever felt awe and delight upon first experiencing a
	computer interface?  An interface that surprised you with its
	strangeness, with a sense of entering an alien world?
      </p>

      <p>
	Some people experience this when they play imaginative video
	games, such as <em>Portal</em>, <em>Monument Valley</em>,
	or <em>The Witness</em>.  For some people, it occurs when they
	first understand how a spreadsheet program can be used to
	model a company, an industry, or even an entire country.  And
	for some people, it occurs when they first use a programming
	language based on particularly powerful ideas, such as Haskell
	or Lisp.
      </p>

      <p>
        My own first experience of this awe and delight was when I
        used the program <em>MacPaint</em>.
      </p>

      <p>
	I was 11 years old.  Up to that point, my experience of
        computers was with command line interfaces, such as the Apple
        II, IBM PC, and Commodore 64:
      </p>

      <center><img src="assets/C64.gif" width="500"/></center>
      
      <p>
	To do graphical work was complicated.  On my Commodore 64, I
	would sometimes make games, using graph paper to sketch out
	the pixels in my game characters, before translating them into
	a sequence of numeric values for input into the computer.  It
	was detailed, painstaking work.
      </p>

      <p>
	One day, my parents took me to an Apple dealership.  There, we
	saw a machine called the Macintosh, running a program
	called <em>MacPaint</em>.  Using a new-to-me pointing device
	called a mouse, I could sketch much more directly on a virtual
	canvas.  I remember feeling awe when I clicked on a region,
	and <em>MacPaint</em> filled the region in.  It knew where the
	borders were!  <em>MacPaint</em> also provided FatBits, a way
	to magnify the drawing, so it could be edited pixel by
	pixel. Most magical of all: if I made a mistake, I could undo
	the mistake with a click of the mouse button, returning the
	canvas to its previous state.
      </p>

      <p>
	<em>MacPaint</em> gave me a direct connection to my drawing,
	similar to using pencils or paints.  But it also provided new
	tools making it easy to do things that were formerly difficult
	or impossible.  Today, such tools are familiar, and perhaps
	seem banal.  But for me they were an epiphany, transforming
	what it meant to draw.
      </p>

      <p>
	Of course, most people have not had the particular
	transformative experience I had with <em>MacPaint</em>.  But I
	believe many people have been awed and delighted
	by <em>some</em> interface.
      </p>

      <p>
	In extreme cases, to use such an interface is to enter a new
	world, containing objects and actions unlike any you've
	previously seen.  At first these elements seem strange.  But
	as they become familiar, you internalize the elements of this
	world.  Eventually, you become fluent, discovering powerful
	and surprising idioms, emergent patterns hidden within the
	interface.  You begin to think <em>with</em> the interface,
	learning patterns of thought that would formerly have seemed
	strange, but which become second nature.  The interface begins
	to disappear, becoming part of your consciousness.  You have
	been, in some measure, transformed.
      </p>

      <h2>What makes an interface transformational?</h2>
      
      <p>
	Of course, most interfaces aren't nearly as striking as these
	examples.  But the existence of such extreme examples
	challenges us to answer the question: what makes an interface
	transformational?
      </p>
      
      <P>
	To answer that question, it helps to consider another
	transformational technology, namely, language.  Children, of
	course, acquire the basics of language in just a few years.
	It's remarkable to watch as a child hears an unfamiliar word
	for the first time, and then a little later speaks that word
	aloud.  Somehow, they're internalizing an external phenomenon
	for their own use.
      </p>

      <p>
	Language is an example of a <em>cognitive technology</em>: an
	external artifact, designed by humans, which can be
	internalized, and used as a vehicle for thought. It's a kind
	of substrate for cognition.
      </p>

      <p>
	Language isn't the only cognitive technology we can
	internalize.
      </p>

      <p>
	Consider visual thinking.  If, like me, you sometimes think
	visually, it's tempting to imagine that your mind's eye is a
	raster display, capable of conceiving any image.  But while
	this is tempting, it's wrong.  In fact, our visual thinking is
	constrained by the visual cognitive technologies we've
	internalized.
      </p>

      <p>
	While this claim hasn't yet been proved by cognitive science,
	in conversation with artists and designers I've found it to be
	a common point of view.  One of the world's best-known art
	teachers, <a href="https://en.wikipedia.org/wiki/Betty_Edwards">Betty
	Edwards</a>, claims that the visual thinking of most adults is
	limited to a simple &ldquo;symbol system&rdquo;, and that this
	constrains both what they see and what they can visually
	conceive:
      </p>
      
      <blockquote>
	<em>[A]dult students beginning in art generally do not really
	  see what is in front of their eyes &mdash; that is, they do
	  not perceive in the way required for drawing.  They take
	  note of what's there, and quickly translate the perception
	  into words and symbols mainly based on the symbol system
	  developed throughout childhood and on what they know about
	  the perceived object.</em>
      </blockquote>

      <p>
	It requires extraordinary imagination to conceive new forms of
	visual meaning.  Indeed, many of our best-known artists and
	visual explorers are famous in part because they discovered
	such forms.  When exposed to that work, other people can
	internalize those new visual cognitive technologies, and so
	expand the range of their visual thought.
      </p>

      <p>
	For example, cubist artists such as Picasso developed the
	technique of using multiple points of view in a single
	painting.  Once you've learnt to see cubist art, it can give
	you a richer sense of the structure of what's being shown:
      </p>

      <center><img src="assets/Picasso1910.jpg"></center>

      <p>
	Another example is the work
	of <a href="https://en.wikipedia.org/wiki/Harold_Eugene_Edgerton">Doc
	Edgerton</a>, a pioneer of high-speed photography, whose
	photographs revealed previusly unsuspected structure in the
	world.  If you study Edgerton's photographs, you begin to
	build new mental models of everyday phenomena, enlarging
	your range of visual thought:
      </p>

      <center><img src="assets/Edgerton1964.jpg"></center>

      <p>
	A large class of examples comes from the many
	cartographers who've developed ways to visually represent
	geography. Consider
	the <a href="https://en.wikipedia.org/wiki/Babylonian_Map_of_the_World">Babylonian
	Map of the World</a>, which introduced the audacious idea of
	depicting the <em>entire</em> world known at the time:
      </p>

      <center><img src="assets/Babylonian_map.jpg" width="400"></center>

      <p>
	Or consider the 1933 map of the London Underground, developed
	by Harry Beck.  In the early 1930s, Beck noticed that the
	official map of the Underground was growing too complex for
	readers to understand.  He greatly simplified the map by
	abandoning exact geographic fidelity, as used on most maps up
	to that point, and concentrating on showing the topological
	structure of the network of stations, i.e., what connects to
	what:
      </p>

      <center><img src="assets/Underground1933_web.jpg" width="600"/></center>

      <p>
	Images such as these are not natural or obvious.  No-one would
	ever have these visual thoughts without the cognitive
	technologies developed by Picasso, Edgerton, Beck, and many
	other pioneers.  But once those technologies are known, we can
	all learn to think in these new ways.
      </p>

      <p>
	In a similar way, imaginative computer interface designers can
	introduce radically new objects and operations.  Users of the
	interface can internalize those objects and operations, and
	use them as new
	<em>elements in their cognition</em>.  That is, they're new
	ways we can think.  We can depict this process of
	internalization as follows:
      </p>

      <span class="marginnote">XXX: There are many problems here with
      nomenclature.

	<br><br> First, I leave up in the air the relationship between
	external elements of cognition and cognitive technologies.

	<br><br>It's tempting to replace "external elements of
	cognition" by "cognitive technologies" in the top line.  But
	there are a couple of problems.

	<br><br> First, an external element of cognition is implicitly
	a single thing.  It might be the fill tool in MacPaint, for
	instance.  While a cognitive technology may refer to a single
	thing, or to an integrated collection.  So an internal element
	of cognition will not in general be an internalization of a
	cognitive technology.

	<br><br>Second, we can internalize things which are just
	naturally occurring, not really technologies at all.  Broadly
	construed, science is about finding ways of internalizing the
	external world.  For many of our most powerful cognitive
	technologies &ndash; say, differential forms &ndash; it's hard
	to say to what extent they are "naturally occurring" versus
	being "technologies".

	<br><br>One approach would be to stick with the current
	description, but: (a) to explain separately how external
	elements of cognition relate to cognitive technologies; (b)
	make this point about elements of cognition being relatively
	singular things, sort of "single thoughts"; (c) explain
	separately this point about the fact that we can internalize
	things which are on the boundary of science and technology.
	Note that (c) needs some refinement; I'm not yet quite clear
	on what I want to say.

	<br><br> It's possible I could simplify my life by introducing
	relatively fixed definitions.  In the current draft I've left
	things pretty vague.  That's good for early exploratory work,
	but it makes it tough to nail things down!

	<br><br>Another significant issue is that I use the term
	"representation" a lot later on.  It's not clear how this
	relates to these other terms.  Ditto the terms "interface",
	"object" and "operation".  I need to work through all these.

      <br><br>That's a lot of problems!  I think the only solution is
      to keep hammering away at these, and to gradually find solutions
      I can live with.  I suspect the solution I eventually adopt will
      be relatively simple. </span>
      <div style="margin: 30px 0 30px 0;">
	<center>
	  <strong><span style="font-size: 1.3em;">External element of cognition</span></strong>
	  <br/>
	  
	  (Our focus is on the objects and operations in computer
	  interfaces, although there are many others) <br/>
	  
	  <strong><span style="font-size: 2em;">&darr;</span></strong>
	  
	  <br/>
	  <strong><span style="font-size: 1.3em;">Internal element of cognition</span></strong>

	  <br/>
	  (A mental pattern used as part of our thinking)
	</center>
      </div>

      <p>
	In this view, our world and culture supply us with a range of
	extant external elements of cognition.  These are the building
	blocks which, when internalized, we use to think.  But they
	occupy only a tiny fraction of the range of all possible
	elements of cognition.  And thus sufficiently imaginative
	interface designers can actually invent new elements of
	cognition:
      </p>

      <center><img src="assets/possible_vs_extant_elements.png"></center>
      
      <p>
	When they do this, they actually expand the range of thoughts
	we can think.  It was such an expansion that
	made <em>MacPaint</em> so exciting: it expanded the range of
	ways I could think visually.  More generally, what makes an
	interface transformational is when it introduces new elements
	of cognition that enable powerful new modes of thought.
      </p>

      <h2>How can we invent new elements of cognition?</h2>
	
      <p>
	Of course, most interfaces are much less exciting.  They're
	built from standard elements, and don't introduce any powerful
	new elements of cognition.  Are there good heuristics to help
	us invent new elements of cognition?
      </p>

      <p>
	As a way of getting insight into that question, I will begin
	by showing a prototype interface.  It's a prototype for
	exploring one-dimensional motion, that is, the motion of a
	particle on a line.  To avoid disappointment, let me say that
	this prototype isn't transformative in the same way
	as <em>MacPaint</em>.  It's rough, a first sketch of an idea.
	But, as we'll discuss below, it illustrates two useful
	heuristics which can help us invent new elements of cognition.
      </p>
      
      <p>
	Note that this prototype is aimed at people who've taken an
	introductory physics class.  That means familiarity with ideas
	such as the potential and kinetic energy of a particle.  If
	you've less background in physics, I hope the gist is
	accessible.  If you've more background, please put yourself
	back in the mindframe of a relative beginner.
      </p>

      <p>
	Note also that the prototype begins with some background
	explanation, before showing an actual interface.  Here it
	is:*<span class="marginnote">* XXX: When this essay ships, the
	JavaScript demo will be replaced by a video with a voiceover
	of the text captions.  This means the bounding box, captions,
	  and controls will all be omitted.</span>
      </p>

      <center>
	<div class="demo" style="width: 720px; height: 620px;">
	  <div id="energy" style="width: 720px; height: 500px; font-size: 18px;"></div>
	  <div id="energy_message" class="demo_message"></div>
	  <div class="demo_button_container" style="left: calc(50% - 60px);">
	    <button id="energy_back" class="demo_button">&larr;</button>
	    &nbsp;&nbsp;
	    <button id="energy_forward" class="demo_button">&rarr;</button>
	  </div>
	  <div class="demo_button_container" style="right: 10px;">
	    <button id="energy_rerun" class="demo_button">&orarr;</button>
	  </div>
	</div>
	<script src="js/energy.js"></script>
      </center>

      <h3>Heuristic 1: Find hidden representations and reify them in the interface</h3>
      
      <p>
	To understand the motivation behind this prototype, consider
	the
	following <a href="http://mathoverflow.net/questions/38639/thinking-and-explaining">question</a>
	from the mathematician William Thurston:
      </p>

      <blockquote>
	<em>How big a gap is there between how you think about
	  mathematics and what you say to others?  Do you say what
	  you're thinking?&hellip;
	  
	  <br><br>I'm under the impression that mathematicians often have
	  unspoken thought processes guiding their work which may be
	  difficult to explain, or they feel too inhibited to try&hellip;
	  
	  <br><br>Once I mentioned this phenomenon to Andy Gleason; he
	  immediately responded that when he taught algebra courses, if
	  he was discussing cyclic subgroups of a group, he had a mental
	  image of group elements breaking into a formation organized
	  into circular groups.
	  
	  <br><br>He said that 'we' never would say anything like that
	  to the students.
	  
	  <br><br>His words made a vivid picture in my head, because it
	  fit with how I thought about groups.  I was reminded of my long
	  struggle as a student, trying to attach <strong>meaning</strong>
	  to 'group', rather than just a collection of symbols, words,
	  definitions, theorems and proofs that I read in a textbook.
	</em>
      </blockquote>

      <p>
	We can paraphrase Thurston as saying that mathematicians often
	don't think about mathematical objects using the standard
	representations found in books.  Rather, they rely heavily on
	what we might call <em>hidden</em> representations, such as
	the mental imagery Thurston describes, of groups breaking into
	formations of circular groups.  Such hidden representations
	help them reason more easily than the conventional
	representations found in books, and occasionally provide them
	with seemingly magical levels of insight.
      </p>

      <p>
	This use of hidden representations occurs in many fields, not
	just mathematics.  For example, electrical engineer Gerald
	Sussman
	has <a href="https://www.infoq.com/presentations/We-Really-Dont-Know-How-To-Compute">observed</a>
	the following about understanding electric circuits:
      </p>

      <blockquote>
	I was teaching my first classes in electrical engineering at
	MIT, in circuit theory&hellip; and I observed that what we
	taught the students wasn't at all what the students were
	actually expected to learn.  That is, what an expert person
	did when presented with a circuit&hellip; was quite different
	from what we tell [the students] to write down &ndash; the
	node equations&hellip; and then you're supposed to grind these
	equations together somehow and solve them, to find out what's
	going on. Well, you know, that's not what a really good
	engineer does.  What a good engineer does is [&hellip;]
      </blockquote>

      <p>
	At this point, Sussman goes into a long, informal analysis.
	It's fascinating, and unlike anything I heard in my electric
	circuits class.  I won't quote Sussman's analysis here &ndash;
	it really needs his voice and body language &ndash; but you
	can see it just after the 26 minute mark
	in <a href="https://www.infoq.com/presentations/We-Really-Dont-Know-How-To-Compute">his
	talk</a>. Sussman concludes:
      </p>

      <blockquote>
	And every real engineer does that.  And that was not the sort
	of thing which we were teaching the students.
      </blockquote>

      <p>
	The energy surface prototype is based on just the kind of
	hidden representation that Thurston and Sussman describe.  In
	particular, it's based on the way I often visualize
	one-dimensional motion, in my work as a theoretical physicist.
	These visuals are not original to me: when I show the
	prototype to professional physicists, I often get the response
	&ldquo;Oh, I think about one-dimensional motion like
	this&rdquo;.  Optimists often append: &ldquo;I've always
	wanted to see this done explicitly!&rdquo; While pessimists
	will add: &ldquo;there's nothing new here, everyone thinks
	this way&rdquo;.
      </p>
      
      <p>
	But while this way of understanding may be common among
	professional physicists, it's not something they usually talk
	about much.  When teaching this material, I might make a few
	sketches along these lines for students.  But they're
	ancillary, a digression.  I do not put this way of thinking
	front and center, nor do I expect students to answer homework
	or exam questions using energy surfaces.  And I would not use
	such a representation in a research paper.
      </p>

      <p>
	The situation is strange.  A powerful way of thinking about
	one-dimensional motion is largely absent from our shared
	conversations.  And the reason is that traditional media are
	poorly adapted to working with such representations.  This
	prototype challenges us to consider building an interface
	which explicitly makes energy surfaces central to how we think
	and communicate about one-dimensional motion.
      </p>

      <p>
	Such an interface would go far beyond the prototype I've
	shown. It would integrate energy surfaces with the traditional
	approach to one-dimensional motion, based on differential
	equations and Newton's laws.  It would thus combine both
	traditional and novel elements of cognition.  And it would be
	a medium useful for both exploration and communication.  The
	resulting medium would transform how we think about
	one-dimensional motion.
      </p>

      <p>
	One-dimensional motion is an important but specialized
	subject.  What about other subjects?  Are there other hidden
	representations used by experts, but not in general use?  What
	were Gleason and Thurston imagining when they thought about
	mathematical groups?  Can we tease those ideas out, and use
	them to inspire interface ideas?  What about Sussman's way of
	thinking about electric circuits?  Perhaps we can take some of
	the representations
	<a href="http://mathoverflow.net/questions/25983/intuitive-crutches-for-higher-dimensional-thinking">mathematicians
	use</a> for thinking about high-dimensional geometry, and turn
	those into an interface?  What about other subjects?  I've
	used examples from physics and mathematics because that's my
	training, but I believe that for most subjects of any depth,
	experts have hidden representations that could inspire
	powerful new interface ideas reifying those representations.
      </p>

      <p>
	I suspect a particularly good source of such representations
	is what I call <em>minimal canonical examples</em>.  Experts
	often have a stock of simple, concrete examples that they use
	to quickly reason in a way that generalizes.  For instance,
	suppose you watch a mathematician as they work on some problem
	in high-dimensional geometry or topology.  They may be
	reasoning about many spatial dimensions &ndash; maybe even an
	infinite number! &ndash; and yet chances are that their rough
	working notes will be filled with diagrams of objects in 2 and
	3 dimensions.  Those diagrams help the mathematician think,
	standing-in for the higher-dimensional objects.  They often
	make use of special ideas that help the mathematician reason.
	For example, the mathematician Vitali
	Milman <a href="http://mathoverflow.net/posts/26010/revisions">likes
	to</a> think about high-dimensional convex bodies using
	diagrams showing a sort of &ldquo;spiky&rdquo; object, like
	the following:
      </p>

      <center>
	<img src="assets/Milman.png" width="300"/>
      </center>

      <p>
	This appears rather strange, since convex bodies are by
	definition bodies that bulge outward everywhere, like a convex
	lens.  They certainly aren't spiky, with inward curves.  But
	Milman uses this representation to remind himself of an
	extremely important and non-inuitive fact about
	high-dimensional convex bodies: nearly all their volume is
	near their surface.  In 2 or 3 dimensions that fact is much
	more accurately represented by a spiky body, like that shown
	above, than it is by a 2-or-3-dimensional convex body, and
	that's part of why Milman finds it a useful aid to thought.
      </p>
      
      <p>
	Experts often have many such minimal canonical examples,
	together with a body of heuristics they can use to reason
	quickly about the example.  Those heuristics are often
	quick-fire rules of thumb, full of exceptions and special
	clauses, not rigorous proof techniques.  They let experts
	quickly sketch out arguments, and figure out what is likely
	true, and what is likely false.  In short, they're a way of
	exploring quickly.
      </p>

      <p>
	This contrasts with most work on reasoning in computer
	systems.  For instance, much of the work on doing mathematics
	by computer has focused on automating symbolic computation
	(<em>Mathematica</em>), or on finding rigorous mathematical
	proofs (<em>Coq</em>). In both cases, the focus is on correct
	mathematical reasoning.  Yet in creative mathematical work
	&ndash; and creative work in other fields &ndash; the supply
	of rigorously correct proofs is merely the last (and often
	least interesting) stage of the creative process.  The
	majority of the creative process is instead concerned with
	rapid exploration relying more on heuristics and rules of
	thumb than on rigorous proof.  There's a kind of logic of
	heuristic discovery that supports exploration.  Such a logic
	is essential to developing powerful exploratory interfaces.
	I've done some preliminary investigations of what a logic of
	heuristic discovery may look like
	in <a href="http://cognitivemedium.com/emm/emm.html">Toward an
	Exploratory Medium for Mathematics</a>.
      </p>

      <p>
	If experts often develop their own hidden representations, why
	don't they share those representations?  It's not that the
	experts are secretive.  Rather, suppose you think hard about a
	subject for several years &ndash; say, cyclic subgroups of a
	group, to use Thurston's example.  Eventually you push up
	against the limits of existing representations.  If you're
	strongly motivated &ndash; say, by the desire to solve some
	challenging research problem &ndash; you begin trying to
	invent new representations, to help provide insights difficult
	in traditional representations.  You are, in a sense, acting
	as your own interface designer.  But the new representations
	you develop are entirely internal, and so not constrained by
	the forms of traditional static media.  As a result, they may
	be difficult to communicate within traditional static media.
	And so they remain private, or perhaps are merely communicated
	informally with other expert colleagues.
      </p>

      <h3>Heuristic 2: Deep principles about the world can be reified
      as interface ideas</h3>
	
      <p>
	In the traditional approach to one-dimensional motion, the
	principle of conservation of energy is written in an algebraic
	form, as:
      </p>

      <p class="equation">
	&frac12; <em>m</em> <em>v</em><sup>2</sup> + <em>U(x)</em> = constant
      </p>

      <p>
	In an expert's hands this is a powerful representation.
	However, it has many shortcomings.  The connections of this
	representation to motion are implicit, not explicit: we don't
	directly see space or velocity or the particle's trajectory;
	we don't directly see the potential or the energy. By
	contrast, the energy surface interface makes these things
	explicit and easy to manipulate.  This makes it effortless to
	pose and answer questions that require much work in the
	algebraic representation.  In this sense, the energy surface
	interface provides a much more direct representation of the
	principle of conservation of energy.
      </p>

      <p>
	Don't confuse this with the (false, in general) idea that
	&ldquo;visual representations are good, algebraic
	representations are bad&rdquo;.  There is a cargo cult
	mentality which embraces visual representation for the sake of
	visual representation.  In fact, there is no <em>a priori</em>
	reason visual representations are superior.  Rather, one must
	understand both the benefits and deficits of any specific
	representation.
      </p>

      <p>
	A good demonstration of this is the beautiful
	book <a href="https://mitpress.mit.edu/sites/default/files/titles/content/sicm/book.html">Structure
	and Interpretation of Classical Mechanics</a>, by Sussman and
	Wisdom.  The book explains the ideas of classical mechanics
	through the medium of Lisp programs.  In our terms, the book
	implements a new interface to classical mechanics, complete
	with many interesting new elements of cognition.  It provides
	powerful new ways of thinking about classical mechanics, but
	is not a visual interface.
      </p>
	
      <p>
	Returning to conservation of energy and the energy surface
	prototype, there's a useful heuristic here: any deep principle
	is an opportunity to create powerful interface ideas.  Every
	theorem of mathematics, every significant result of science,
	is a challenge to our imagination as interface designers.  Can
	we find ways of expressing these principles in an interface?
	What new objects and new operations does a principle suggest?
	What <em>a priori</em> surprising relationship between those
	objects and operations are revealed by the principle?  Can we
	find interfaces which vividly reveal those relationships,
	preferably in a way that is unique to the phenomenon being
	studied?  By answering these questions, we can turn what was a
	surprising and non-intuitive principle into a source of
	intuition and novel understanding.
      </p>

      <p>
	A second example illustrating this heuristic of reifying deep
	ideas is <a href="http://euclidthegame.come">Euclid: the
	Game</a>, by Kasper Peulen.  It's a game inspired by the
	ancient Greek mathematicians, who attempted to use things like
	rulers and compasses to construct geometric figures.  Let's
	take a look: <em>(XXX: this is currently implemented in an iframe,
	which has to be manually stepped through, as per the script in
	the next paragraph.  In the shipping version of the essay this
	will be done as a video.)</em></span>:
      </p>

      <iframe src="http://euclidthegame.com/Level1/"
	      width="1000" height="900" style="transform: scale(0.8)";>
      </iframe>

      <p>
	<strong>Script:</strong> <em>
	  In this first level, we're challenged to construct an
      equilateral triangle, starting from the line segment AB.  To do
      this, we're given a few simple tools, shown here.  For instance,
      we can use a compass tool to draw a circle.  Or this tool lets
      us draw a line segment between two points.  Or this tool lets us
      find the point intersecting two lines.  To construct an
      equilateral triangle, we first use the compass tool to draw a
      circle with A at the center, and B on the perimeter.  Then we
      use the compass tool again to draw a circle with B at the
      center, and A on the perimeter.  Then we intersect the two
      circles, and draw line segments.  In this way we successfully
      construct an equilateral triangle, and move on to level 2, which
      is a harder challenge.  Note, though, that if we look closely at
      the toolbar, we see that an extra tool has been added: a tool to
      construct an equilateral triangle.  Let me cheat a bit, and skip
      ahead some levels, to level 25.  What you see is that along the
      way to level 25, we add many tools to the toolbar.  And some are
      quite sophisticated, giving us the ability to do things like
      bisect angles, construct a perpendicular, and so on.  With our
      initial tools it's non-trivial to figure out how to do these
      things.  And so Euclid: the Game is actually integrating quite
      deep principles into the interface.
	</em>
      </p>

      <p>
	One point <em>Euclid: the Game</em> illustrates is that as we
	build the deep principles of a subject into an interface, then
	mastering the interface coincides more and more with mastering
	the subject*<span class="marginnote">* I discuss this also
	in <a href="http://cognitivemedium.com/emm/emm.html">Toward an
	Exploratory Medium for Mathematics</a> (2016).</span>. Another
	example is the program <em>Photoshop</em>, which builds in
	many deep principles that can be used to do image
	manipulation.  A person who masters <em>Photoshop</em>'s
	interface is usually well along the way to becoming an expert
	in image manipulation.  Similarly, someone who masters the
	interfaces in <em>Structure and Interpretation of Classical
	Mechanics</em> is well on the way to mastering classical
	mechanics.  It's interesting to contrast these with the
	interface in a program such as
	<em>Microsoft Word</em>, which contains few deep principles
	about writing. That makes it possible to
	master <em>Word</em>'s interface without becoming even a
	passable writer.  This isn't a criticism of <em>Word</em>;
	rather, the issue is that we have few really powerful ideas
	about how to be a good writer.
      </p>

      <!--  XXX: criticisms
      <p>
	Although <em>Euclid: the Game</em> incorporates many deep
	principles, it provides few ways for us limited in our ability
	to work with those ideas.  There is, for example, no facility
	to re-examine constructions, and to understand variations and
	improvements.  Nonetheless, it's a fun example of how powerful
	ideas can be built into an interface.
      </p>

      -->
      
      <p>
	Let me finish this section by showing another prototype
	interface.  This time it's a prototype to help think about
	two-dimensional projectile motion.  Although that may sound
	like a subject similar to the first prototype, it's a very
	different subject, and the interface is, accordingly, very
	different.  It's also much more ambitious than the prototype
	for one-dimensional motion, in that I'll use it to address a
	problem I didn't know how to solve before building the
	interface.  Let's take a look:
      </p>

      
      <center>
	<div class="demo" style="relative; width: 700px; height: 620px;">
	  <div id="projectile" style="width: 700px; height: 500px; font-size: 18px;"></div>
	  <div id="projectile_message" class="demo_message"></div>
	  <div class="demo_button_container" style="left: calc(50% - 60px)">
	    <button id="projectile_back" class="demo_button">&larr;</button>
	    &nbsp;&nbsp;
	    <button id="projectile_forward" class="demo_button">&rarr;</button>
	  </div>
	  <div class="demo_button_container" style="right: 10px;">
	    <button id="projectile_rerun" class="demo_button">&orarr;</button>
	  </div>
	</div>
	<script src="js/projectile.js"></script>
      </center>

      <p>
	As with the energy surface prototype, this prototype is based
	on a representation &ndash; in this case, the fan of
	trajectories &ndash; familiar to many experts, but not known
	to most students of physics.  What's more this fan is a based
	on a fundamental theorem of mechanics, expressing the range of
	trajectories that can pass through a particular point.  And
	so, again, our two heuristics are helping us devise powerful
	interface ideas.
      </p>

      <p>
	One notable thing about the energy surface and projectile
	prototypes is how different they are.  In the traditional
	algebraic approach, one- and two-dimensional motion are
	represented in similar ways.  But that similarity is
	superficial and misleading.  In fact, very different ideas are
	useful to understand motion in one and two dimensions.  For
	instance, the trajectory fan is very useful in two dimensions,
	but much less useful in one dimension, where all the particle
	can do is move back and forward on the line.  As another
	example, in one dimension the trajectories are completely
	determined by the principle of conservation of energy.  In two
	dimensions, the situation is more complicated, and the
	principle is much less informative than in one dimnsion.
	Differences like these are obscured in the traditional
	representation, and experts take years to really internalize
	them.  But in interfaces reifying the deepest ideas about a
	system, these differences are immediately
	evident*<span class="marginnote">* XXX: A problem in this
	paragraph is that I use trajectory to mean both a trajectory
	in x-v space, and in position space alone.</span>.
      </p>

	
      <h2>Conclusion</h2>

      <p>
	In the 1960s and 1970s, Douglas Engelbart, J. C. R. Licklider,
	Alan Kay, and others developed a vision of computers as
	devices for augmenting and extending human beings.  This
	vision strongly influenced later researchers and entrepreneurs
	&ndash; perhaps no-one more importantly than Steve Jobs
	&ndash; and has now entered mainstream media accounts.
      </p>

      <p>
	A common informal model of augmentation is what we might call
	the <em>cognitive outsourcing</em> model: we specify a
	problem, send it to our device, which solves the problem,
	perhaps in a way we-the-user don't understand, and sends back
	a solution:
      </p>

      <center>
	<img src="assets/outsourcing_model.svg"/>
      </center>

      <p>
	So, for example, if I want to know the distance to the moon, I
	send the question to Google, which sends back an answer:
      </p>

      <center><img src="assets/outsourcing_question.png"/></center>

      <p>
	Or I can ask Google Maps the route from my office to Berkeley:
      </p>

      <center><img src="assets/outsourcing_map.png"/></center>

      <p>
	Many people implicitly or explicitly use this cognitive
	outsourcing model to think about augmentation.  It is the most
	common model used in press accounts.  It is also, I believe, a
	common way for programmers to think about augmentation.
      </p>

      <p>
	In this essay, we've seen a different way of thinking about
	augmentation.  Rather than just solving problems, the goal is
	to develop entirely new elements of cognition:
      </p>

      <center><img src="assets/possible_vs_extant_elements.png"></center>

      <p>
	Thus, we're not merely changing what problems we can easily
	solve.  We're actually changing the thoughts we can think.
      </p>

      <p>
        The imagining of new elements of cognition is one of the main
        events in computing.  It's a job for imaginative cognitive
        engineers who can conceive new elements which open up new
        mental worlds.
      </p>

      <p>
	In one sense, it's the reverse of what a scientist does.
	Scientists try to figure out the rules underlying this world.
	But we're trying to find new rules which underly profound new
	worlds, with striking emergent behaviors, expanding and
	augmenting human capability.
      </p>

      <p>
	One of the challenges in work on intelligence augmentation is
	that the outcomes are so difficult to imagine.  What new
	elements of cognition can we invent?  How will they affect the
	way the human race thinks?  We cannot know until they've been
	invented.
      </p>

      <p>
	As an analogy, compare today's attempts to go to Mars with the
	exploration of the oceans during the great age of discovery.
	These appear similar, but while Mars is an extremely specific,
	concrete goal, the seafarers of the 15th through 18th
	centuries didn't know what they would find.  They set out in
	flimsy boats, with vague plans, hoping to find something worth
	the risks.  In that sense, it was even more difficult than
	today's attempts on Mars*<span class="marginnote">* This
	analogy was suggested to me in conversation
	  by <a href="http://www.tophtucker.com/">Toph Tucker</a>.</span>.
      </p>

      <p>
	And so it is with intelligence augmentation.  There are many
	worthwhile goals in technology, with very specific ends in
	mind.  Artificial intelligence, life extension, and so on.
	These are solid, concrete goals.  By contrast, intelligence
	augmentation is much harder to imagine.  There's no specific
	intelligent box or life-extension therapy to imagine.  Rather,
	by changing the elements of our cognition, we can expand the
	range of thoughts we can think.  But we cannot say <em>a
	priori</em> how that expansion will happen, or what it will
	bring.  But what we can do is to ask good questions, and to
	explore boldly.
      </p>

	
      <h2>Acknowledgements</h2>

      <p>
	Thanks to David Albert, Hannah Davis, Chaim Gingold, May-Li
	Khoe, Hassan Masum, Andy Matuschak, Robert Ochshorn, Caitlin
	Sikora, and Toph Tucker for discussion of the ideas that led
	to this essay.  This work was begun at
	the <a href="http://www.recurse.com">Recurse Center</a>, and
	completed at <a href="http://ycr.org">YC Research</a>.
      </p>

      <h2>Citation</h2>

      <p>
	In academic work, please cite this essay as: <em>Michael
	  Nielsen, &ldquo;Thought as a Technology&rdquo;, available
	  at <a href="http://cognitivemedium.com/tat/index.html">http://cognitivemedium.com/tat/index.html</a>
	  (2016)</em>.
      </p>

      <!--
	  
	<h2>Background Reading</h2>

      <p>
	Detailed references have been provided inline and in margin
	notes.  However, some overall influences have been omitted, in
	part because they relate less to specific points than to
	overall point of view.  I've collected the most significant of
	these here.
      </p>
      
      <p>
	The entire essay is strongly influenced by the ideas of Lev
	Vygotsky.  Through his body of work, Vygotsky was a key figure
	developing the notion of internalizing models found in the
	external world, and then appropriating those models for use in
	our own cognition.
      </p>

      <p>
	The idea of using computers to create new (micro-)worlds was
	described strikingly in Seymour Papert's book
	&ldquo;Mindstorms&rdquo;.
      </p>

      This essay arose out of my attempt to make sense of the work of
      some of the great interface designers, including people such as
      Douglas Engelbart, Alan Kay, Bret Victor.  What is an interface
      designer doing?
      

      Wittens.  Victor.
      
      ISSUES

      I don't have to address all these issues.  But they are
      naturally raised by the essay.  And so it's worth spending some
      time thinking about them.

      Issue: Put in "imagination" arrows into my bubble diagram.
      
      Issue: Aphantasia.  I've claimed that we internalize external
      phenomena we're exposed to, and we use those internalized models
      to think.  This does not mean we can internalize any external
      phenomenon.  Sufferers of aphantasia have no mind's eye, and
      presumably don't learn to think visually.  In general, it is
      interesting to ponder the limits to our ability to internalize
      what we see in the world.

      Issue: I (perhaps) don't sufficiently emphasize the importance of
      discovery.  Why does this matter?

      Issue: I haven't precisely explained what I mean by an element of
      cognition.

      Bundle of issues: I don't distinguish very well between cognitive
      technologies and elements of cognition.  In fact, I think there's a
      whole lot of issues here, and they're global issues with the whole
      essay.  I really need to work on brainstorming the issues, figuring
      out solutions I'm happy with, and then correcting the whole essay.  It
      may take a while!  I talk a lot about representations.  Again, it's
      not so clear what is going on.

      Issue: am I over-using the word powerful?

      Issue: I don't particularly like the discussion of what makes an
      element of cognition powerful.  I should write out some criticisms of
      the discussion, and respond to them.

      Issue: will we become trapped by the elements of cognition used
      by an interface?  Might that be a bad thing?  Yes, it is
      potentially a bad thing.  Thurston again: that quote on the
      value of new representations (via Wittens).  If new
      representations are important, then it's helpful to work within
      platforms that enable people thing.  The right resolution for
      creative work is, I believe, to ensure that there's no
      distinction

      Issue: I showed this prototype to one physicist who teaches
      pre-med students at university.  He said he suspected his
      students would find the prototype intriguing, but would prefer
      to continue working with algebra.  I believe there's some truth
      to this: by that point, they've 10 years experience with
      algebra.  They're successful students, who've been told they're
      good with algebra, and they've built up some confidence.


      Issue: where do these powerful representations come from?  In
      particular, how do experts develop them?

      Issue: How essential is the fact that the external elements are
      dynamic, and have their own behavior?
      



      Make sure to address the "thoughts we could not previously have
    thought".

    In what sense does it make sense to say language is an actual
    cognitive technology?

    Issue: what do I want to do with the following material?

    Issue: I state: "This makes it effortless to pose and answer
    questions that require much work in the algebraic representation."
    But I don't say exactly what.  A partial answer is that we build
    up a direct sense of how changing the potential changes the
    trajectories.  This isn't a single fact, but is rather a way of
    immediately perceiving an infinite variety of facts: how making
    such-and-such a change to the trajectory here, causes that change
    to the trajectory there.

      Issue: How does knowing the trajectory relate to understanding
      the motion?
      
          <p>
	A particularly striking formulation of the cognitive
	outsourcing model is due to the cognitive scientist
	<a href="https://en.wikipedia.org/wiki/David_Kirsh">David
	Kirsh</a>*<span class="marginnote">* David
	Kirsh, <a href="assets/kirsh2010.pdf">Thinking with external
	representations</a>, AI and Society (2010).</span>:
      </p>
      
      <blockquote>
	<em>Cognitive processes flow to wherever it is cheaper to
	  perform them. The human &lsquo;cognitive operating
	  system&rsquo; extends to states, structures, and processes
	  outside the mind and body&hellip; Processes should migrate
	  to wherever they are best, or most easily, performed.</em>
      </blockquote>

    </div>

    <p class="next">
      This being the University of Chicago, we might perhaps think of
      this as a cognitive analogue of the efficient market
      hypothesis. Call it the <em>efficient augmented mind
      hypothesis</em>.
    </p>

    Issue: Haven't we been inventing new elements of cognition
    forever?  Is there anything really new about using computers?  Old
    representations were static.  In computers, the forms can respond
    to the user, and they can actively compute.  Each of these is a
    fundamental change.

    Issue: Introduce the following material:
    
      <p>
	Let me show an example of a more recent interface that
	introduces novel elements of cognition.  It's a prototype
	medium developed by the interface
	designer <a href="http://worrydream.com">Bret Victor</a>.  The
	prototype sketches a medium for working with difference
	equations.  While it's not a full production environment, it
	nonetheless contains some striking ideas.  Take a look:
      </p>

      <center>
	<iframe src="http://player.vimeo.com/video/85480838?portrait=0"
		width="800" height="500" frameborder="0" webkitallowfullscreen
		mozallowfullscreen allowfullscreen></iframe>
      </center>

      <p>
	This prototype introduces many new ways of understanding
	difference equations: highlighted regions which you can
	manipulate; search; tying variables together; many-way flows
	of information between the algebraic expressions, the graph,
	and the search box; and so on.  Each introduces one or more
	new elements of cognition.
      </p>

      <p>
	These elements combine to give a feeling of ease in
	exploration, of having powerful new ways to think.  It's
	plausible that if you worked extensively in a fully-developed
	version of this environment, it would transform how you think
	about difference equations.
      </p>

      <p>
	What makes some elements of cognition particularly powerful?
      </p>

      <p>
	A good working definition is that an element of cognition is
	powerful if it makes some important creative or intellectual
	acts much easier.
      </p>

      <p>
	So, for instance, maps are powerful because they make it
	easier to answer questions like &ldquo;What's the shortest
	route between the Kew Gardens and Watford Junction Underground
	stations&rdquo;?  With a good map of the Underground this is
	an easy question to answer.  But if all you had was a written
	list of stations, it'd likely be quite difficult.
      </p>

      <p>
	In a similar way, Bret Victor's medium for studying difference
	equations is powerful because it makes things easy that would
	be hard in conventional representations.  XXX.
      </p>

      Issue: Find all spots that sound like hype, and remove or
      somehow cut the hype.

      Issue ("but what about realism?") In many areas of technology,
      fidelity to the real world is an important goal.  For example,
      many people working on gaming, special effects, and virtual
      reality work extremely hard to achieve high fidelity.  Observe,
      however, that inventing new elements of cognition is largely
      orthogonal to this goal.  Consider language, maps, and musical
      notation: all are highly stylized.  No uncanny valley is crossed
      in reaching a platonic musical staff.  

      assumes fidelity to the real world to be a core goal.  For
      example, this is true in much work on gaming, graphics, and
      virtual reality.  Inventing new elements of cognition is largely
      orthogonal to this goal.  The alphabet bears no great fidelity
      to any real world system; no uncanny valley has been crossed to
      reach a platonic "letter A".  And yet written words are at the
      core of how we think.  For this reason I am skeptical of some
      work in VR, which presumes that the additional realism makes it
      a superior platform.  It is only superior insofar as it enables
      the invention of new elements of cognition.

      With that said, there are some benefits to great realism.
      Consider the uncanny valley.  When successfully crossed, the
      benefits are enormous: we can use CG systems to create emotional
      responses.  You can look at a character and see a particular
      kind of grief; that evinces a particular emotional response.
      Think of it as a new emotional affordance.


      Issue: I don't say enough about examples of new elements of
      cognition in computing.

      Issue: Do I want to have a general discussion?  

      Issue: Why focus on interfaces?

      Issue: How could we make this a medium for both communication
      and exploration?

      Issue: I don't really say what the benefits of the energy
      surface medium are.  I think it's that we can change the
      potential and immediately see how the trajectories 

      Issue: Old-fashioned elements of cognition are static.  They
      don't compute.  How does it matter that these can?  It certainly matters

      Issue: How does it affect my story that 

      Issue: How should I ask people to cite this?  

      Issue: Bret objects to some of my comment: rather than using
	hidden representations, shouldn't we go back and think from
	first principles?  Of course, I agree, in the sense that
	mining hidden representations is just one heuristic.  It'd be
	worth doing both things!  Actually, I expect that reifying the
	hidden representations will help with the other task, too.

      Issue: Where do these hidden representations come from?

      Issue: What are the limits of the representations we have
      available?
      
    Possibilities to ask for feedback: Maneesh.  Martin and Fernanda.
    Andy.  Devon, Xavier.  Vi.  Emily.  Julia. Nic. Patrick, Nic,
    Andy, Vi, Emily.  Tim Gowers.  Alan Kay.  Bret Victor.  Dan
    Ingalls.

          After publication, send to: Tim O'Reilly. Tyler Cowen.  Ken
          Perlin.

      Co-evolution of our thinking and our interfaces.  Will all
      knowledge workers gradually become interface developers?  This
      is already happening in many fields.  In many case, though, it's
      not happening.

      Will we develop open science journals that lets us build these
      interface ideas in?
      

      The notion of lots of bespoke interfaces. I've suggested that a
      good way of getting interesting interface ideas is to  

      The notion of discovery as a litmus test.

      In the body of the essay I've got a half-baked comment,
      commented out (but marked with an XXX) about how Euclid is
      limited.  I should revisit this and see what I want to do.

      I'm writing this for liminal people, i.e., people on the edge of
      doing this.  Nicky Case.  Guillermo Valle.  Devon. Omar.
      Katherine.  Toph.
      
      -->
    </div>

    <div id="footer">
      This work is licensed under a <a rel="license"
	 href="http://creativecommons.org/licenses/by/4.0/">Creative
	 Commons Attribution 4.0 International License</a>.  This
	 means you're free to copy, share, and build on the work,
	 provided you attribute it appropriately.  Please click on
	 the following license link for details: <a rel="license"
	 href="http://creativecommons.org/licenses/by/4.0/"><img alt="Creative
	 Commons License" style="border-width: 0; height: 24px;" 
	 src="https://i.creativecommons.org/l/by/4.0/88x31.png"/></a>
    </div>
  </body>
</html>
      
